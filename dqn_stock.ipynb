{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/ElegantRL/blob/master/eRL_demo_StockTrading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1gUG3OCJ5GS"
   },
   "source": [
    "# **Stock Trading Application in ElegantRL**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGXyBBvL0dR2"
   },
   "source": [
    "# **Part 1: Problem Formulation**\n",
    "Formally, we model stock trading as a Markov Decision Process (MDP), and formulate the trading objective as maximization of expected return:\n",
    "\n",
    "\n",
    "\n",
    "*   **State s = [b, p, h]**: a vector that includes the remaining balance b, stock prices p, and stock shares h. p and h are vectors with D dimension, where D denotes the number of stocks. \n",
    "*   **Action a**: a vector of actions over D stocks. The allowed actions on each stock include selling, buying, or holding, which result in decreasing, increasing, or no change of the stock shares in h, respectively.\n",
    "*   **Reward r(s, a, s’)**: The asset value change of taking action a at state s and arriving at new state s’.\n",
    "*   **Policy π(s)**: The trading strategy at state s, which is a probability distribution of actions at state s.\n",
    "*   **Q-function Q(s, a)**: the expected return (reward) of taking action a at state s following policy π.\n",
    "*   **State-transition**: After taking the actions a, the number of shares h is modified, as shown in Fig 3, and the new portfolio is the summation of the balance and the total value of the stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jESlu_WtD_JS"
   },
   "source": [
    "# **Part 2: Stock Trading Environment Design**\n",
    "\n",
    "**State Space and Action Space**\n",
    "\n",
    "\n",
    "*   **State Space**: We use a 181-dimensional vector consists of seven parts of information to represent the state space of multiple stocks trading environment: [b, p, h, M, R, C, X], where b is the balance, p is the stock prices, h is the number of shares, M is the Moving Average Convergence Divergence (MACD), R is the Relative Strength Index (RSI), C is the Commodity Channel Index (CCI), and X is the Average Directional Index (ADX).\n",
    "*   **Action Space**: As a recap, we have three types of actions: selling, buying, and holding for a single stock. We use the negative value for selling, positive value for buying, and zero for holding. In this case, the action space is defined as {-k, …, -1, 0, 1, …, k}, where k is the maximum share to buy or sell in each transaction.\n",
    "\n",
    "\n",
    "**Easy-to-customize Features**\n",
    "\n",
    "\n",
    "*   **initial_capital**: the initial capital that the user wants to invest.\n",
    "*   **tickers**: the stocks that the user wants to trade with.\n",
    "*   **initial_stocks**: the initial amount of each stock and the default could be zero.\n",
    "*   **buy_cost_pct, sell_cost_pct**: the transaction fee of each buying or selling transaction.\n",
    "*   **max_stock**: the user is able to define the maximum number of stocks that are allowed to trade per transaction. Users can also set the maximum percentage of capitals to invest in each stock.\n",
    "*   **tech_indicator_list**: the list of financial indicators that are taken into account, which is used to define a state.\n",
    "*   **start_date, start_eval_date, end_eval_date**: the training and backtesting time intervals. Thee time dates (or timestamps) are used, once the training period is specified, the rest is backtesting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbamGVHC3AeW"
   },
   "source": [
    "# **Part 3: Install ElegantRL and related packages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVdmpnK_3Zcn"
   },
   "source": [
    "# **Part 4: Import Packages**\n",
    "\n",
    "\n",
    "*   **ElegantRL**\n",
    "*   **yfinance**: yfinance aims to solve this problem by offering a reliable, threaded, and Pythonic way to download historical market data from Yahoo! finance.\n",
    "*   **StockDataFrame**: stockstats inherits and extends pandas.DataFrame to support Stock Statistics and Stock Indicators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1VM1xKujoz-6"
   },
   "outputs": [],
   "source": [
    "from elegantrl.run import *\n",
    "from elegantrl.agent import AgentDQN\n",
    "from elegantrl.envs.FinRL.StockTrading import StockTradingEnv, check_stock_trading_env\n",
    "import yfinance as yf\n",
    "from stockstats import StockDataFrame as Sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n8zcgcn14uq"
   },
   "source": [
    "# **Part 5: Specify Agent and Environment**\n",
    "\n",
    "*   **args.agent**: firstly chooses one DRL algorithm to use from agent.py. In this application, we prefer to choose DDPG and PPO agent.\n",
    "*   **args.env**: creates the environment, and the user can either customize own environment or preprocess environments from OpenAI Gym and PyBullet Gym from env.py. In this application, we create the self-designed stock trading environment.\n",
    "\n",
    "\n",
    "> Before finishing initialization of **args**, please see Arguments() in run.py for more details about adjustable hyper-parameters.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_pickle('StockTradingEnv_processed_data.df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5284"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d[(d.date < '2021-01-01') & (d.date >= '2016-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d[(d.date >= '2008-03-19') & (d.date < '2016-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.936384</td>\n",
       "      <td>1.004464</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.860883</td>\n",
       "      <td>535796800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.927237</td>\n",
       "      <td>0.721947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.860883</td>\n",
       "      <td>0.860883</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.987723</td>\n",
       "      <td>0.903460</td>\n",
       "      <td>0.788302</td>\n",
       "      <td>512377600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>0.927237</td>\n",
       "      <td>0.721947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.824592</td>\n",
       "      <td>0.824592</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0.926339</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.799837</td>\n",
       "      <td>778321600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001717</td>\n",
       "      <td>0.894348</td>\n",
       "      <td>0.738334</td>\n",
       "      <td>14.119612</td>\n",
       "      <td>-24.602649</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.816341</td>\n",
       "      <td>0.816341</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>0.947545</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.730621</td>\n",
       "      <td>767972800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.004215</td>\n",
       "      <td>0.901703</td>\n",
       "      <td>0.688118</td>\n",
       "      <td>7.524634</td>\n",
       "      <td>-133.333333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.794911</td>\n",
       "      <td>0.794911</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.852679</td>\n",
       "      <td>0.765229</td>\n",
       "      <td>460734400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.004106</td>\n",
       "      <td>0.885194</td>\n",
       "      <td>0.692754</td>\n",
       "      <td>25.518884</td>\n",
       "      <td>-88.553561</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.788974</td>\n",
       "      <td>0.788974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>131.320007</td>\n",
       "      <td>133.460007</td>\n",
       "      <td>131.100006</td>\n",
       "      <td>131.773087</td>\n",
       "      <td>54930100</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "      <td>3.332375</td>\n",
       "      <td>133.084918</td>\n",
       "      <td>116.348350</td>\n",
       "      <td>61.315724</td>\n",
       "      <td>171.392618</td>\n",
       "      <td>31.194296</td>\n",
       "      <td>122.326539</td>\n",
       "      <td>119.069382</td>\n",
       "      <td>0.026951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>133.990005</td>\n",
       "      <td>137.339996</td>\n",
       "      <td>133.509995</td>\n",
       "      <td>136.486053</td>\n",
       "      <td>124486200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>3.801722</td>\n",
       "      <td>134.689237</td>\n",
       "      <td>116.751032</td>\n",
       "      <td>64.485587</td>\n",
       "      <td>203.530539</td>\n",
       "      <td>40.801655</td>\n",
       "      <td>122.908336</td>\n",
       "      <td>119.403902</td>\n",
       "      <td>1.259002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>138.050003</td>\n",
       "      <td>138.789993</td>\n",
       "      <td>134.339996</td>\n",
       "      <td>134.668762</td>\n",
       "      <td>121047300</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>3.981151</td>\n",
       "      <td>135.718903</td>\n",
       "      <td>117.301006</td>\n",
       "      <td>62.444536</td>\n",
       "      <td>179.324440</td>\n",
       "      <td>43.929288</td>\n",
       "      <td>123.427893</td>\n",
       "      <td>119.770764</td>\n",
       "      <td>0.307219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>135.580002</td>\n",
       "      <td>135.990005</td>\n",
       "      <td>133.399994</td>\n",
       "      <td>133.520477</td>\n",
       "      <td>96452100</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "      <td>3.984758</td>\n",
       "      <td>136.575356</td>\n",
       "      <td>117.542911</td>\n",
       "      <td>61.178808</td>\n",
       "      <td>138.858632</td>\n",
       "      <td>38.845768</td>\n",
       "      <td>123.874559</td>\n",
       "      <td>120.060675</td>\n",
       "      <td>0.151054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>134.080002</td>\n",
       "      <td>134.740005</td>\n",
       "      <td>131.720001</td>\n",
       "      <td>132.492020</td>\n",
       "      <td>99116600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "      <td>3.860132</td>\n",
       "      <td>137.138659</td>\n",
       "      <td>117.939175</td>\n",
       "      <td>60.051022</td>\n",
       "      <td>109.885663</td>\n",
       "      <td>30.069064</td>\n",
       "      <td>124.317231</td>\n",
       "      <td>120.388933</td>\n",
       "      <td>0.128471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5284 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close     volume  \\\n",
       "0     2000-01-03    0.936384    1.004464    0.907924    0.860883  535796800   \n",
       "1     2000-01-04    0.966518    0.987723    0.903460    0.788302  512377600   \n",
       "2     2000-01-05    0.926339    0.987165    0.919643    0.799837  778321600   \n",
       "3     2000-01-06    0.947545    0.955357    0.848214    0.730621  767972800   \n",
       "4     2000-01-07    0.861607    0.901786    0.852679    0.765229  460734400   \n",
       "...          ...         ...         ...         ...         ...        ...   \n",
       "5279  2020-12-24  131.320007  133.460007  131.100006  131.773087   54930100   \n",
       "5280  2020-12-28  133.990005  137.339996  133.509995  136.486053  124486200   \n",
       "5281  2020-12-29  138.050003  138.789993  134.339996  134.668762  121047300   \n",
       "5282  2020-12-30  135.580002  135.990005  133.399994  133.520477   96452100   \n",
       "5283  2020-12-31  134.080002  134.740005  131.720001  132.492020   99116600   \n",
       "\n",
       "       tic  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
       "0     AAPL    0  0.000000    0.927237    0.721947   0.000000  -66.666667   \n",
       "1     AAPL    1 -0.001628    0.927237    0.721947   0.000000  -66.666667   \n",
       "2     AAPL    2 -0.001717    0.894348    0.738334  14.119612  -24.602649   \n",
       "3     AAPL    3 -0.004215    0.901703    0.688118   7.524634 -133.333333   \n",
       "4     AAPL    4 -0.004106    0.885194    0.692754  25.518884  -88.553561   \n",
       "...    ...  ...       ...         ...         ...        ...         ...   \n",
       "5279  AAPL    3  3.332375  133.084918  116.348350  61.315724  171.392618   \n",
       "5280  AAPL    0  3.801722  134.689237  116.751032  64.485587  203.530539   \n",
       "5281  AAPL    1  3.981151  135.718903  117.301006  62.444536  179.324440   \n",
       "5282  AAPL    2  3.984758  136.575356  117.542911  61.178808  138.858632   \n",
       "5283  AAPL    3  3.860132  137.138659  117.939175  60.051022  109.885663   \n",
       "\n",
       "           dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0     100.000000      0.860883      0.860883    0.000000  \n",
       "1     100.000000      0.824592      0.824592    0.000000  \n",
       "2     100.000000      0.816341      0.816341    0.000000  \n",
       "3     100.000000      0.794911      0.794911    0.000000  \n",
       "4     100.000000      0.788974      0.788974    0.000000  \n",
       "...          ...           ...           ...         ...  \n",
       "5279   31.194296    122.326539    119.069382    0.026951  \n",
       "5280   40.801655    122.908336    119.403902    1.259002  \n",
       "5281   43.929288    123.427893    119.770764    0.307219  \n",
       "5282   38.845768    123.874559    120.060675    0.151054  \n",
       "5283   30.069064    124.317231    120.388933    0.128471  \n",
       "\n",
       "[5284 rows x 17 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E03f6cTeajK4",
    "outputId": "2e47cb16-baa0-487d-ca71-ac6c2d249e6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| load data: .//StockTradingEnv_processed_data.df\n",
      "processed df length: 5284\n",
      "split results 1962\n",
      "split results 1259\n",
      "| price_ary.shape: (1962,), tech_ary.shape: (1962, 8), turbulence_ary.shape: (1962,)\n",
      "| price_ary.shape: (1259,), tech_ary.shape: (1259, 8), turbulence_ary.shape: (1259,)\n",
      "| load data: .//StockTradingEnv_processed_data.df\n",
      "processed df length: 5284\n",
      "split results 1962\n",
      "split results 1259\n",
      "| price_ary.shape: (1962,), tech_ary.shape: (1962, 8), turbulence_ary.shape: (1962,)\n",
      "| price_ary.shape: (1259,), tech_ary.shape: (1259, 8), turbulence_ary.shape: (1259,)\n"
     ]
    }
   ],
   "source": [
    "# Agent\n",
    "args = Arguments(if_on_policy=False)\n",
    "args.agent = AgentDQN()\n",
    "\n",
    "# Environment\n",
    "tickers = ['AAPL']  # finrl.config.NAS_74_TICKER\n",
    "\n",
    "tech_indicator_list = [\n",
    "  'macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30',\n",
    "  'close_30_sma', 'close_60_sma']  # finrl.config.TECHNICAL_INDICATORS_LIST\n",
    "\n",
    "gamma = 0.99\n",
    "max_stock = 1\n",
    "initial_capital = 1e6\n",
    "initial_stocks = 0\n",
    "buy_cost_pct = 1e-3\n",
    "sell_cost_pct = 1e-3\n",
    "start_date = '2008-03-19'\n",
    "start_eval_date = '2016-01-01'\n",
    "end_eval_date = '2021-01-01'\n",
    "\n",
    "args.env = StockTradingEnv('./', gamma, max_stock, initial_capital, buy_cost_pct, \n",
    "                           sell_cost_pct, start_date, start_eval_date, \n",
    "                           end_eval_date, tickers, tech_indicator_list, \n",
    "                           initial_stocks, if_eval=False)\n",
    "args.env_eval = StockTradingEnv('./', gamma, max_stock, initial_capital, buy_cost_pct, \n",
    "                           sell_cost_pct, start_date, start_eval_date, \n",
    "                           end_eval_date, tickers, tech_indicator_list, \n",
    "                           initial_stocks, if_eval=True)\n",
    "\n",
    "args.env.target_reward = 3\n",
    "args.env_eval.target_reward = 3\n",
    "\n",
    "# Hyperparameters\n",
    "args.gamma = gamma\n",
    "args.break_step = 10000\n",
    "args.net_dim = 2 ** 9\n",
    "args.max_step = args.env.max_step\n",
    "args.max_memo = 1000\n",
    "args.batch_size = 32\n",
    "args.repeat_times = 4 # repeat_times * target_step == number of times we update before training\n",
    "args.eval_gap = 2 ** 4\n",
    "args.eval_times1 = 2 ** 3\n",
    "args.eval_times2 = 2 ** 5\n",
    "args.if_allow_break = True\n",
    "args.rollout_num = 2 # the number of rollout workers (larger is not always faster)\n",
    "args.target_step = 200 # number of exploration steps before training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1j5kLHF2dhJ"
   },
   "source": [
    "# **Part 6: Train and Evaluate the Agent**\n",
    "\n",
    "> The training and evaluating processes are all finished inside function **train_and_evaluate_mp()**, and the only parameter for it is **args**. It includes the fundamental objects in DRL:\n",
    "\n",
    "*   agent,\n",
    "*   environment.\n",
    "\n",
    "> And it also includes the parameters for training-control:\n",
    "\n",
    "*   batch_size,\n",
    "*   target_step,\n",
    "*   reward_scale,\n",
    "*   gamma, etc.\n",
    "\n",
    "> The parameters for evaluation-control:\n",
    "\n",
    "*   break_step,\n",
    "*   random_seed, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGOPSD6da23k",
    "outputId": "2fdbfc4b-80a2-4659-ace5-b3bde0f36d8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| GPU id: 0, cwd: ./AgentDQN/StockTradingEnv-v1_0\n",
      "| Remove history\n",
      "ID      Step      MaxR |    avgR      stdR       objA      objC |  avgS  stdS\n",
      "start exploring before training\n",
      "Begin updating network before training\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-28f454bd012d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the training process will terminate once it reaches the target reward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/School and University/Harvard Masters/STAT234/project/ElegantRL/elegantrl/run.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplore_before_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Begin updating network before training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat_times\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pre-training and hard update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'act_target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcri_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cri_target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/School and University/Harvard Masters/STAT234/project/ElegantRL/elegantrl/agent.py\u001b[0m in \u001b[0;36mupdate_net\u001b[0;34m(self, buffer, target_step, batch_size, repeat_times)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mq_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_critic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_step\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrepeat_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mobj_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_obj_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcri_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/School and University/Harvard Masters/STAT234/project/ElegantRL/elegantrl/agent.py\u001b[0m in \u001b[0;36mget_obj_critic_raw\u001b[0;34m(self, buffer, batch_size)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mnext_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcri_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mq_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnext_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/elegentrl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/School and University/Harvard Masters/STAT234/project/ElegantRL/elegantrl/net.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Q value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/elegentrl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/elegentrl/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/elegentrl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/elegentrl/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/elegentrl/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \"\"\"\n\u001b[0;32m-> 1368\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(args) # the training process will terminate once it reaches the target reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPXOxLSqh5cP"
   },
   "source": [
    "Understanding the above results::\n",
    "*   **Step**: the total training steps.\n",
    "*  **MaxR**: the maximum reward.\n",
    "*   **avgR**: the average of the rewards.\n",
    "*   **stdR**: the standard deviation of the rewards.\n",
    "*   **objA**: the objective function value of Actor Network (Policy Network).\n",
    "*   **objC**: the objective function value (Q-value)  of Critic Network (Value Network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6jvgYPnHMpf"
   },
   "source": [
    "# **Part 7: Backtest and Draw the Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3jCdezgzQUhh",
    "outputId": "a1ea5861-1ce9-4d44-c94d-3c236eb48428"
   },
   "outputs": [],
   "source": [
    "args = Arguments(if_on_policy=True)\n",
    "args.agent = AgentPPO()\n",
    "args.env = StockTradingEnv(cwd='./', if_eval=True)\n",
    "args.if_remove = False\n",
    "args.cwd = './AgentPPO/StockTradingEnv-v1_0'\n",
    "args.init_before_training()\n",
    "\n",
    "env.draw_cumulative_return(args, torch)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "eRL_demo_StockTrading.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
