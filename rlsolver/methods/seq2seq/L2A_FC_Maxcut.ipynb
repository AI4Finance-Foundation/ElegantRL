{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZnMakuU_mFW"
      },
      "source": [
        "## Utils and loading graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbYI3kDwec3w"
      },
      "source": [
        "Read Graph from text using networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxRTVa8YecKY"
      },
      "outputs": [],
      "source": [
        "from typing import List, Union\n",
        "from torch import Tensor\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from tqdm import tqdm  #progress bars for loops and iterables\n",
        "\n",
        "# read graph file, e.g., BarabasiAlbert_100_ID2, as networkx.Graph\n",
        "def read_nxgraph(filename: str) -> nx.Graph():\n",
        "    graph = nx.Graph()\n",
        "    is_first_line = True\n",
        "    for line in filename:\n",
        "        if is_first_line:\n",
        "            strings = line.split(\" \")\n",
        "            num_nodes = int(strings[0])\n",
        "            num_edges = int(strings[1])\n",
        "            nodes = list(range(num_nodes))\n",
        "            graph.add_nodes_from(nodes)\n",
        "            is_first_line = False\n",
        "        else:\n",
        "            node1, node2, weight = line.split(\" \")\n",
        "            # nodes in file start from 1, change to from 0 in our codes.\n",
        "            graph.add_edge(int(node1) - 1, int(node2) - 1, weight=weight)\n",
        "    return graph\n",
        "\n",
        "# get the adjacency matrix\n",
        "def transfer_nxgraph_to_adjacencymatrix(graph: nx.Graph):\n",
        "    return nx.to_numpy_array(graph)\n",
        "\n",
        "# calculate cut value\n",
        "def obj_maxcut(solution: Union[Tensor, List[int], np.array], graph: nx.Graph):\n",
        "    num_nodes = len(solution)\n",
        "    obj = 0\n",
        "    adj_matrix = transfer_nxgraph_to_adjacencymatrix(graph)\n",
        "    #loop through upper-right half of the adjacency matrix and calculate cut value\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(i + 1, num_nodes):\n",
        "            if solution[i] != solution[j]:\n",
        "                obj += adj_matrix[(i, j)]\n",
        "    return obj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grxExpkvhXS9"
      },
      "source": [
        "Load data (hard-coded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYD7rwdnhWz8"
      },
      "outputs": [],
      "source": [
        "BarabasiAlbert_100_ID2 = \"\"\"100 384\n",
        "1 2 1\n",
        "1 3 1\n",
        "1 4 1\n",
        "1 5 1\n",
        "1 6 1\n",
        "1 7 1\n",
        "1 8 1\n",
        "1 9 1\n",
        "1 10 1\n",
        "1 23 1\n",
        "1 26 1\n",
        "1 30 1\n",
        "1 31 1\n",
        "1 33 1\n",
        "1 45 1\n",
        "1 46 1\n",
        "1 48 1\n",
        "1 54 1\n",
        "1 65 1\n",
        "1 68 1\n",
        "1 69 1\n",
        "1 74 1\n",
        "1 76 1\n",
        "1 91 1\n",
        "1 97 1\n",
        "2 6 1\n",
        "2 33 1\n",
        "2 42 1\n",
        "2 60 1\n",
        "2 62 1\n",
        "3 6 1\n",
        "3 7 1\n",
        "3 8 1\n",
        "3 28 1\n",
        "3 29 1\n",
        "3 43 1\n",
        "3 47 1\n",
        "3 51 1\n",
        "3 57 1\n",
        "3 74 1\n",
        "3 87 1\n",
        "3 91 1\n",
        "3 96 1\n",
        "3 98 1\n",
        "3 99 1\n",
        "4 6 1\n",
        "4 7 1\n",
        "4 9 1\n",
        "4 10 1\n",
        "4 11 1\n",
        "4 17 1\n",
        "4 28 1\n",
        "4 29 1\n",
        "4 32 1\n",
        "4 44 1\n",
        "4 46 1\n",
        "4 49 1\n",
        "4 61 1\n",
        "4 68 1\n",
        "4 72 1\n",
        "4 84 1\n",
        "4 97 1\n",
        "4 99 1\n",
        "5 8 1\n",
        "5 11 1\n",
        "5 12 1\n",
        "5 15 1\n",
        "5 16 1\n",
        "5 17 1\n",
        "5 24 1\n",
        "5 35 1\n",
        "5 38 1\n",
        "5 53 1\n",
        "5 57 1\n",
        "6 7 1\n",
        "6 8 1\n",
        "6 9 1\n",
        "6 18 1\n",
        "6 22 1\n",
        "6 23 1\n",
        "6 24 1\n",
        "6 25 1\n",
        "6 26 1\n",
        "6 39 1\n",
        "6 52 1\n",
        "6 55 1\n",
        "6 74 1\n",
        "6 76 1\n",
        "6 91 1\n",
        "7 9 1\n",
        "7 10 1\n",
        "7 11 1\n",
        "7 12 1\n",
        "7 13 1\n",
        "7 14 1\n",
        "7 15 1\n",
        "7 17 1\n",
        "7 20 1\n",
        "7 28 1\n",
        "7 29 1\n",
        "7 37 1\n",
        "7 51 1\n",
        "7 54 1\n",
        "7 63 1\n",
        "7 93 1\n",
        "7 95 1\n",
        "8 10 1\n",
        "8 13 1\n",
        "8 16 1\n",
        "8 28 1\n",
        "8 34 1\n",
        "8 42 1\n",
        "8 43 1\n",
        "8 60 1\n",
        "8 61 1\n",
        "8 66 1\n",
        "8 90 1\n",
        "9 12 1\n",
        "9 18 1\n",
        "9 19 1\n",
        "9 21 1\n",
        "9 33 1\n",
        "9 46 1\n",
        "9 50 1\n",
        "9 68 1\n",
        "9 70 1\n",
        "9 83 1\n",
        "10 11 1\n",
        "10 14 1\n",
        "10 15 1\n",
        "10 23 1\n",
        "10 27 1\n",
        "10 30 1\n",
        "10 32 1\n",
        "10 38 1\n",
        "10 50 1\n",
        "10 56 1\n",
        "10 59 1\n",
        "10 68 1\n",
        "10 74 1\n",
        "10 75 1\n",
        "10 81 1\n",
        "10 85 1\n",
        "10 86 1\n",
        "10 94 1\n",
        "11 12 1\n",
        "11 13 1\n",
        "11 14 1\n",
        "11 20 1\n",
        "11 21 1\n",
        "11 25 1\n",
        "11 34 1\n",
        "11 35 1\n",
        "11 39 1\n",
        "11 41 1\n",
        "11 43 1\n",
        "11 44 1\n",
        "11 51 1\n",
        "11 52 1\n",
        "11 53 1\n",
        "11 63 1\n",
        "11 69 1\n",
        "11 79 1\n",
        "11 89 1\n",
        "11 92 1\n",
        "11 94 1\n",
        "12 13 1\n",
        "12 14 1\n",
        "12 16 1\n",
        "12 18 1\n",
        "12 19 1\n",
        "12 25 1\n",
        "12 27 1\n",
        "12 30 1\n",
        "12 31 1\n",
        "12 32 1\n",
        "12 33 1\n",
        "12 36 1\n",
        "12 38 1\n",
        "12 39 1\n",
        "12 40 1\n",
        "12 48 1\n",
        "12 49 1\n",
        "12 54 1\n",
        "12 60 1\n",
        "12 67 1\n",
        "12 79 1\n",
        "12 83 1\n",
        "12 85 1\n",
        "12 88 1\n",
        "13 15 1\n",
        "13 20 1\n",
        "13 23 1\n",
        "13 25 1\n",
        "13 42 1\n",
        "13 43 1\n",
        "13 50 1\n",
        "13 57 1\n",
        "13 58 1\n",
        "13 73 1\n",
        "13 75 1\n",
        "13 82 1\n",
        "14 17 1\n",
        "14 18 1\n",
        "14 20 1\n",
        "14 21 1\n",
        "14 22 1\n",
        "14 31 1\n",
        "14 36 1\n",
        "14 37 1\n",
        "14 47 1\n",
        "14 49 1\n",
        "14 59 1\n",
        "14 63 1\n",
        "14 69 1\n",
        "14 81 1\n",
        "14 83 1\n",
        "14 86 1\n",
        "14 97 1\n",
        "15 16 1\n",
        "15 19 1\n",
        "15 22 1\n",
        "15 35 1\n",
        "15 38 1\n",
        "15 44 1\n",
        "15 80 1\n",
        "16 22 1\n",
        "16 26 1\n",
        "16 27 1\n",
        "16 29 1\n",
        "16 51 1\n",
        "16 58 1\n",
        "17 19 1\n",
        "17 64 1\n",
        "17 88 1\n",
        "18 26 1\n",
        "18 52 1\n",
        "18 55 1\n",
        "18 73 1\n",
        "19 44 1\n",
        "19 45 1\n",
        "19 47 1\n",
        "19 52 1\n",
        "19 60 1\n",
        "19 70 1\n",
        "19 84 1\n",
        "19 91 1\n",
        "20 21 1\n",
        "20 35 1\n",
        "20 45 1\n",
        "20 72 1\n",
        "20 73 1\n",
        "20 85 1\n",
        "20 95 1\n",
        "20 98 1\n",
        "20 100 1\n",
        "21 24 1\n",
        "21 31 1\n",
        "21 37 1\n",
        "21 41 1\n",
        "21 66 1\n",
        "22 36 1\n",
        "22 48 1\n",
        "22 66 1\n",
        "22 71 1\n",
        "22 77 1\n",
        "22 87 1\n",
        "23 24 1\n",
        "23 32 1\n",
        "23 61 1\n",
        "23 82 1\n",
        "23 90 1\n",
        "23 96 1\n",
        "24 34 1\n",
        "24 54 1\n",
        "24 62 1\n",
        "24 63 1\n",
        "24 86 1\n",
        "25 40 1\n",
        "26 27 1\n",
        "26 41 1\n",
        "26 88 1\n",
        "26 98 1\n",
        "27 81 1\n",
        "27 90 1\n",
        "27 99 1\n",
        "28 30 1\n",
        "28 34 1\n",
        "28 40 1\n",
        "28 61 1\n",
        "28 92 1\n",
        "29 36 1\n",
        "29 49 1\n",
        "29 70 1\n",
        "30 37 1\n",
        "31 41 1\n",
        "31 58 1\n",
        "31 82 1\n",
        "32 56 1\n",
        "32 100 1\n",
        "33 39 1\n",
        "33 65 1\n",
        "33 95 1\n",
        "34 53 1\n",
        "34 67 1\n",
        "34 78 1\n",
        "34 84 1\n",
        "34 89 1\n",
        "34 94 1\n",
        "35 59 1\n",
        "35 86 1\n",
        "36 87 1\n",
        "37 40 1\n",
        "37 45 1\n",
        "37 50 1\n",
        "37 56 1\n",
        "37 59 1\n",
        "37 72 1\n",
        "37 77 1\n",
        "37 88 1\n",
        "38 48 1\n",
        "38 58 1\n",
        "38 64 1\n",
        "38 71 1\n",
        "40 42 1\n",
        "41 85 1\n",
        "42 46 1\n",
        "42 57 1\n",
        "42 67 1\n",
        "42 78 1\n",
        "42 83 1\n",
        "44 47 1\n",
        "44 94 1\n",
        "45 66 1\n",
        "47 53 1\n",
        "47 73 1\n",
        "48 55 1\n",
        "48 62 1\n",
        "50 75 1\n",
        "50 81 1\n",
        "50 89 1\n",
        "51 56 1\n",
        "52 69 1\n",
        "52 71 1\n",
        "52 76 1\n",
        "53 55 1\n",
        "53 71 1\n",
        "53 96 1\n",
        "54 64 1\n",
        "54 84 1\n",
        "54 97 1\n",
        "55 72 1\n",
        "55 78 1\n",
        "56 65 1\n",
        "56 89 1\n",
        "56 92 1\n",
        "56 93 1\n",
        "56 96 1\n",
        "56 99 1\n",
        "57 65 1\n",
        "57 93 1\n",
        "58 64 1\n",
        "58 77 1\n",
        "59 80 1\n",
        "60 62 1\n",
        "61 67 1\n",
        "63 76 1\n",
        "64 90 1\n",
        "64 98 1\n",
        "66 77 1\n",
        "66 92 1\n",
        "67 70 1\n",
        "67 78 1\n",
        "67 79 1\n",
        "68 75 1\n",
        "68 79 1\n",
        "70 87 1\n",
        "74 82 1\n",
        "77 100 1\n",
        "78 80 1\n",
        "79 80 1\n",
        "82 100 1\n",
        "84 95 1\n",
        "87 93 1\"\"\".splitlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq6Gpqgc-5JW"
      },
      "source": [
        "Load graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYfDshMw-4N7"
      },
      "outputs": [],
      "source": [
        "graph = read_nxgraph(BarabasiAlbert_100_ID2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe22bawgGR9z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.distributions as distributions\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ChOJgRAWVA"
      },
      "source": [
        "Initilize lists for experiment tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfRPwwAfAAda"
      },
      "outputs": [],
      "source": [
        "stats_losses = [] # store losses\n",
        "stats_advantages = [] # store the advantages\n",
        "states = [] # store all transitions (step, new score, new solution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfmbGiYm_baX"
      },
      "source": [
        "## Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7UpBd3sfG-U"
      },
      "source": [
        "Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vt5eOtJZpd6"
      },
      "outputs": [],
      "source": [
        "# Fully connected model with only one hidden layer, and a sigmoid head for outputing probability\n",
        "class FCModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FCModel, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
        "        layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        #layers.append(nn.Softmax(dim=1))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdhqQ3mF347d"
      },
      "source": [
        "Define buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v83n0R9ZLerX"
      },
      "outputs": [],
      "source": [
        "# Buffer implementation based on https://github.com/YangletLiu/L2A_Algorithm/blob/4785e79d3f34b77636625f8363685647d1e0e341/graph_max_cut_trs.py#L242\n",
        "# Main change being the update function adds one trajectory instead of multiple trajectories at once.\n",
        "class Buffer:\n",
        "    def __init__(self, buffer_size, trajectory_length, num_nodes, device=torch.device('cpu')):\n",
        "        self.solutions = torch.empty((trajectory_length + 1, buffer_size, num_nodes), dtype=torch.bool)\n",
        "        self.rewards = torch.empty((trajectory_length, buffer_size), dtype=torch.float32)\n",
        "        self.logprobs = torch.empty((trajectory_length, buffer_size), dtype=torch.float32)\n",
        "\n",
        "        self.obj_values = torch.empty(buffer_size, dtype=torch.float32)\n",
        "\n",
        "        self.p = 0\n",
        "        self.add_size = 0\n",
        "        self.buffer_size = buffer_size\n",
        "        self.device = device\n",
        "\n",
        "    def update(self, solution, reward, logprob, obj_value):\n",
        "        # solution.shape == (trajectory_length, num_nodes)\n",
        "        # reward.shape == (trajectory_length)\n",
        "        # logprob.shape == (trajectory_length)\n",
        "\n",
        "        # Add one trajectory\n",
        "        if self.p < self.buffer_size:\n",
        "            self.solutions[:solution.shape[0], self.p] = solution.to(self.device)\n",
        "            self.rewards[:, self.p] = reward.to(self.device)\n",
        "            self.logprobs[:, self.p] = logprob.to(self.device)\n",
        "            self.obj_values[self.p] = obj_value.to(self.device)\n",
        "            self.p += 1\n",
        "\n",
        "        # when the buffer is full, replace the trajectory with lowest score\n",
        "        else:\n",
        "            _, ids = th.topk(self.obj_values[:self.p], k=1, largest=False)\n",
        "            self.states[:, ids] = solution.to(self.device)\n",
        "            self.rewards[:, ids] = reward.to(self.device)\n",
        "            self.logprobs[:, ids] = logprob.to(self.device)\n",
        "            self.obj_values[ids] = obj_value.float().to(self.device)\n",
        "\n",
        "    def sample(self, batch_size, device) :\n",
        "        ids = torch.randint(self.p, size=(batch_size,), requires_grad=False)\n",
        "        return (self.solutions[:, ids].to(device),\n",
        "                self.rewards[:, ids].to(device),\n",
        "                self.logprobs[:, ids].to(device),\n",
        "                self.obj_values[ids].to(device))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVg0lOV8i2Ae"
      },
      "source": [
        "Define local seach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAWCmcihi1Ub"
      },
      "outputs": [],
      "source": [
        "def get_best_neighbor(solution, graph):\n",
        "    max_neighbor = solution.copy()\n",
        "    max_neighbor_score = 0\n",
        "    for i in range(len(solution)):\n",
        "        neighbor = solution.copy()\n",
        "        neighbor[i] = 1 - neighbor[i]\n",
        "        cur_score = obj_maxcut(neighbor, graph)\n",
        "        if cur_score > max_neighbor_score:\n",
        "            max_neighbor = neighbor\n",
        "            max_neighbor_score = cur_score\n",
        "\n",
        "    return max_neighbor, max_neighbor_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zu5wGsge16v"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Initialize Temperature and Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noVN2OLxe0Iu"
      },
      "outputs": [],
      "source": [
        "trajectory_length = 16\n",
        "num_epochs = 10\n",
        "lambda_l = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWqQW4qI2-tX"
      },
      "source": [
        "Initialize state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P46vVPZN297e"
      },
      "outputs": [],
      "source": [
        "num_nodes = graph.number_of_nodes()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah1S2p2pdFoV"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "Initialize model and prepare for training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXb3eCrJZcNu"
      },
      "outputs": [],
      "source": [
        "# initialize model hyperparameters\n",
        "input_dim = num_nodes\n",
        "hidden_dim = 32\n",
        "output_dim = num_nodes  # Output one probality per node\n",
        "\n",
        "buffer_size = 256\n",
        "update_steps = 6\n",
        "batch_size = 24\n",
        "max_local_search_steps=6\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "\n",
        "model = FCModel(input_dim, hidden_dim, output_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "scores = [] # Used to track mean scores at each epoch\n",
        "\n",
        "buffer = Buffer(buffer_size, trajectory_length, num_nodes, device) # initialize buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkxGwGAQADs3"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYoabvkggcN1"
      },
      "source": [
        "Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kowiApDTfaeP",
        "outputId": "6d1f299c-59d2-441a-f01f-4a25c7d39f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "for k in tqdm(range(num_epochs)):\n",
        "    # Decrease lambda_l and at each epoch\n",
        "    lambda_l = lambda_l * (1 - (k + 1) / num_epochs)\n",
        "    # Update the model multiple times for each lambda value\n",
        "    epoch_scores = []\n",
        "\n",
        "    step = 0\n",
        "    while step < update_steps:\n",
        "        # Random initialization of the start of new trajectory\n",
        "        init_solution = [random.choice([0, 1]) for _ in range(num_nodes)]\n",
        "        curr_solution = copy.deepcopy(init_solution)\n",
        "        curr_score = obj_maxcut(curr_solution, graph)\n",
        "        init_score = curr_score\n",
        "\n",
        "        cur_advantage = 0\n",
        "        cur_log_prob = -num_nodes\n",
        "\n",
        "        trajectory_scores = []\n",
        "        trajectory_log_probs = []\n",
        "        trajectory = []\n",
        "\n",
        "        # Sample one trajectory\n",
        "        for t in range(trajectory_length):\n",
        "            # Get output probability distribution from model\n",
        "            model_input = torch.tensor(curr_solution, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            outputs = model(model_input)\n",
        "            outputs = outputs.squeeze(1)\n",
        "\n",
        "            # Sample new state from outputs\n",
        "            m = distributions.Bernoulli(probs=outputs)\n",
        "\n",
        "            new_state = m.sample()\n",
        "            # calculate the log probability of this state\n",
        "            log_prob = m.log_prob(new_state)\n",
        "            log_prob_sum = log_prob.sum()\n",
        "\n",
        "            # Convert new_solution to numpy array\n",
        "            new_solution = new_state.cpu().tolist()[0]\n",
        "            # calculate cut value of the new solution\n",
        "            new_score = obj_maxcut(new_solution, graph)\n",
        "\n",
        "            # Local search\n",
        "            #while 1:\n",
        "            for ls_step in range(max_local_search_steps):\n",
        "                neighbor, neighbor_score = get_best_neighbor(new_solution, graph)\n",
        "                if neighbor_score > new_score:\n",
        "                    new_solution = neighbor\n",
        "                    new_score = neighbor_score\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            epoch_scores.append(new_score)\n",
        "\n",
        "            trajectory_scores.append(new_score)\n",
        "            trajectory_log_probs.append(log_prob_sum)\n",
        "            trajectory.append(new_solution)\n",
        "\n",
        "            # Compute advantage\n",
        "            cur_advantage = cur_advantage + new_score\n",
        "            cur_log_prob = cur_log_prob + log_prob_sum\n",
        "\n",
        "\n",
        "            curr_solution = new_solution\n",
        "            curr_score = new_score\n",
        "\n",
        "        obj_value = -(cur_log_prob * (cur_advantage - lambda_l*cur_log_prob -lambda_l)).detach()\n",
        "        # Store the new trajectory score and log_prob in the buffer\n",
        "        buffer.update(torch.tensor(trajectory),\n",
        "                        torch.tensor(trajectory_scores, dtype=torch.float32),\n",
        "                        torch.tensor(trajectory_log_probs, dtype=torch.float32),\n",
        "                        obj_value)\n",
        "\n",
        "\n",
        "        if buffer.p >= buffer_size/2:\n",
        "            # Sample batch from buffer\n",
        "            buffer_trajectory, buffer_trajectory_scores, buffer_trajector_log_probs, buffer_losses = buffer.sample(batch_size, device)\n",
        "\n",
        "\n",
        "            # Compute loss\n",
        "            # Use dummy to ensure loss has grad_fn\n",
        "            dummy_var = torch.tensor(1.0, requires_grad=True, device=device)\n",
        "            loss = (buffer_losses.mean() * dummy_var).mean()\n",
        "            stats_losses.append(loss.item())\n",
        "            # Backpropagate loss\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            step += 1\n",
        "\n",
        "    # Store mean scores of the epoch\n",
        "    scores.append(np.mean(epoch_scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW7fE3pN7Xm-"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5LNS9RPFkcP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz4P2EuNVpyd"
      },
      "source": [
        "Target score: 287"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ighsF3lukO1W"
      },
      "outputs": [],
      "source": [
        "print(f\"score: {max(epoch_scores)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeVAVH-MadEC"
      },
      "outputs": [],
      "source": [
        "plt.plot(scores)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Scores vs Epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxXhA9avGBx1"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}